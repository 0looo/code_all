jupyter 사용관련 내용
	window 창만 껐을때(powerShell 미종료시) 키는 방법
		: localhost:8888
			# 8888 = 기본적으로 설정하는 port, 만약 사용자가 변경했을 경우 해당하는 port 작성필요

os
	import os
	os.system(#)
		: 명령프롬프트(cmd)에 작성하는 것과 동일한 결과 출력
		
	os.mkdir(폴더명)
		: 폴더 생성

thread
	: 병렬연산을 위한 함수
	import threading
	
	th = threading.Thread(target = function(), args = (function변수))
		: target은 함수를 넣고, 해당함수에 넣을 변수들은 args에 대입하여 thread 지정
	
	th.start()
		: 지정한 thread를 실행
	
	th.join()
		: thread하는 작업이 종료될때까지 기다리게 해주는 함수.
		: 선후관계 해결을 위한 해결책
		
사칙연산
	// : 몫
	% : 나머지
	** : 제곱
	
	math	(library)
		import math

		올림
			math.ceil(#) : #을 올림처리
		내림
			math.floor(#) : #을 내림처리
			
			int() 형변환으로 버림 처리 가능
			
%
	%timeit 측정할코드
		: 걸린시간 출력(속도비교할때 사용)
		
변수지정
	globals()[변수명] = data
		# R에서 assign과 동일한 역활 (assign(변수명, data)와 동일결과)
			
랜덤 추출
	random	(library)
		import random
		random int 추출
			random.randint(startint, endint) : startint ~ endint사이의 정수를 랜덤추출
string
	좌우공백 지우기
		좌우 공백 모두 삭제
			str.strip()
		왼쪽에 있는 공백삭제
			str.lstrip()
		오른쪽에 있는 공백삭제
			str.rstrip()
			
	문자바꾸기
		str.replace('기존문장','대신할문장')
		
	문자입력
		f"...{변수1}...{변수2}..."
			: abc변수1abc변수2로 출력
			: String 앞에 f를 붙히고 함수를 넣기 원하는 위치에 {}를 사용하여서 {}안에 넣어줌.
			** {}(중괄호) 자체를 출력하고 싶을때는 {{}} 으로 작성(중괄호 안에 중괄호를 넣어줌)
			
		"{}...{}".format(1,2..)
			: String에 {}대신에 넣을 값을 순서에 맞게 format()안에 작성해줌.
			
	contains(포함여부, 검색)
		in
			## not in == in의 반대결과 출력
			'검색할단어' in str
				: str에 단어가 있을 경우 True / 없을 경우 False
			
		str.find('찾을단어')
			: 해당단어가 있을 경우 첫번째 index 출력 / 없을 경우 -1 출력
	
	시작단어 확인
		str.startswith('확인할단어')
			: str이 '확인할단어'로 시작하는지 여부 판단(T/F)
	
	종료단어 확인
		str.endswith('확인할단어')
			:str이 '확인할단어'로 종료되는지 여부 판단(T/F)
	문자체우기
		str.zfill(00)
			: 00길이의 string을 만들면서 str을 제외하고 부족한 길이만큼 왼쪽에 0을 추가시킴
			: 00 <= len(str) 인경우 str을 출력함.
		
		str.rjust(00, '체우고싶은문자')
			: 00길이의 string을 만들면서 기존 str의 부족한 길이를 '체우고싶은문자'로 체움 
			# 체우고싶은문자는 한글자만 되며, 00 <= len(str)인경우 str그대로 출력
		
		int + 문자체우기
			format(int, '00')
			'{0:00d}.format(int)'
				: 00개 만큼의 길이를 만들면서 부족한 길이만큼 앞에 0을 붙힘
				: 앞에 0붙히는 함수로 유용함.(월 표시할때 유용)

	String Concatenation (문자열 합치기)
		str1 + str2
			: str1, str2를 합쳐서 출력
		
		'%s%s'%(str1,str2)
			# % str1, str2대신 dict를 넣어 반복하고 싶은경우
				-> '%(key1)s%(key2)s'%dict
		

set
	삽입
		set.add(#)
			: set에 #을 추가
		set.update(list or set..)
			: set에 여러값을 추가할때 사용

list
	생성
		list comprehensdion
			: 대괄호 안에 반복문을 작성하여 list 생성. for문 안에 list.append()를 사용하여 넣는 것보다 빠른 결과 도출 및 코드 단순화를 달성함.
			ex) [i for i in range(10)] ==> [0,1,2,3,4...8,9]인 list 생성
	삽입
		list.append(##)
			: ##를 맨 마지막 인덱스에 넣어줌
			
		list.insert(#, ##)
			: #번 자리에 ##값을 넣음
			
	delete(제거)
		del list명[index번호]
			: index번호를 넣어서 삭제가능
			
		list명.remove(##)
			: list에서 ##을 제거
			: ##가 여러개일경우 가장 앞에 있는 1개를 제거함
			: ##이 없을 경우 error
			
		list.pop(##)
			: ## 을 비워둘경우 맨마지막 요소 출력 및 제거
			: ##에 index값을 넣어서 추출가능
	
	요소 index 확인
		list.index(#)
			: list 내부에 #가 해당하는 요소값 출력, #가 없을 경우 error (ValueError) 발생
			
	list to string		
		'**'.join(list1)
			: list요소 사이에 **를 넣으면서 string으로 출력
	
	sort
		sorted(list, ##)
			: 숫자(오름차순),알파벳(알파벳순서),한글(ㄱ-?)
			## reverse = True
				: 역순으로 정리
			## key = #
				: #에 맞춰서 순서정리
				# = list.find
					: list에 순서에 맞게 (활용 : 중복단어가 뒤어 나올때 원본과 비교하여 다름으로 찾을 수 있음)
					
dict(사전)
	get
		dict.get('key',##)
			: dict에 key가 있을 경우 해당하는 value, 없을 경우 ## 출력
			
DataFrame
	저장
		df.to_csv(파일명, sep = '')
			* sep : 나누는 기준이 별도지정필요할때
				: .tsv파일일 경우 \t 입력

	불러오기
		pd.read_csv(파일명,##)		
			##
			sep : 나누는 기준이 별도지정필요할때
				: .tsv파일일 경우 \t 입력
			parse_dates=[col] : 지정한 col을 datatype으로 출력
			index_col = 0 : 첫col이 Unnamed: 0 일때 삭제해서 출력
			skiprows=00 : 00만큼 row를 skip하고 불러들임
			thousands = ','   : 천자리 ,를 없애서 불러들임
		pd.read_excel(파일명, ##)
			## _csv 동일

	생성
		pd.DataFrame(list or dict , index=['','',...])
			* index갯수만큼 적어줘야 함
			* dict의 경우 keys => col

	병합
		pd.concat([df1, df2], ignore_index = Ture, axis = 1, join = **)
			* list에 DataFrame넣었을 시 concat(list)
			* df을 list에 넣었을때는 list를 넣음
			* ignore_index = Ture   => index를 새로 지정(0~)
			* axis = 0   => 기본값, raw를 추가하는 방식
			  axis = 1   => col을 추가하는 방식
			* join = ''
				1)outer : 기본값, 전체 병합
				2)inner : 동일한 col만

		merge(df1, df2, on=col명, how = **)
			* on => df의 col이 다를때 left_on, right_on 으로 사용가능
			* how
				1)outer 2)inner  3)left  4) right
		
		append
			df1.append(df2, #)
				: pd.concat([df1,df2]와 동일한 결과 출력)
				# 
					ignore_index = True : 기존의 index를 가져오는 성질 없앰.
		
	정보확인
		.info()
		.describe()
			: 갯수, 평균, 표준편차. 최소값~25%..~최대값

	index, column
		.reset_index(#)
			: index를 0 ~ 로 변경
			# drop = True : col추가 방지가능

		df.rename(index = {'index명' : '바꿀index명'..} , columns = {col명:바꿀col명,...}, inplace = True)
			: index, column 명 동시변경가능
			# 원본반영안됨. (inplace하면 가능)

		df.index = ['index명'....]
			: list기준으로 index명 변경

		df.columns = ['col'명...]
			: list기준으로 columns명 변경

	slicing
		df.loc[row명, col명]
			*여러개 선택시 : [[row명, row명..],[col명,col명...]]
			*구간선택시 [ : 가능]

		df.iloc[row번호, col번호]
				*여러개 선택시 : [[row번호, row번호..],[col번호,col번호...]]
			*구간선택시 [ : 가능]

		df[조건] : 조건에 성립하는 값만 출력
			*조건의 출력값이 index의 갯수에 맞게 나와야함
			* and : & / or : | , 조건마다 ()로 묶어야 함.
			*앞에 ~붙이면 not

		df.isin([])
			*.isin() 가로안에 list형식으로 넣어야함, 요소의 정확한 값만 True

		df.drop_duplicates() : 중복row제거

		df['col'].str.contains('str')
			: 문자가 존재하는지 여부 확인

	groupby
		함수
			.get_group('group기준의 요소 중 입력') : 요소가 포함된 row출력 
				*입력값은 1개밖에 안됨.

			.count() : index별 갯수 출력
				* grouped에 col지정안할경우 모든값이 1로 출력

			.mean()
			.sum()
				* grouped에 col지정안할경우 수식함수는 수치col들을 원본으로 출력

		.agg(*)				
			* {col : [**], col :** }
			# 함수만 넣으면 모든col에 적용
			# col마다 수식다르게 적용가능
			# 수식이 복수일 경우 []사용
			** : 'mean', 'std', sum, min, max, len, 'count'...

		.transform(*)
			: 해당하는 col을 원래 df의 index에 맞춰서 값들을 출력

		.apply(*) : .agg()와 동일하지만 agg가 오류날경우 .transform과 동일해짐


		2개 이상 col을 groupby
			.groupby([col명, col명])         * 2개이상일때 []로 col묶어줌
			.unstack() :

	index&column 변경

		index 변경
			df.reindex(list) : list로 df의 index가 변경
				* 원본미반영
				* 기존의 index에 있는 값들은 list순서에 맞게 정렬, 없으면 nan값으로 row생성

			df.set_index(**, inplace = True)  : 해당 col을 index로 변경
				* inplace = True 제거시 원본미반영
				** df['col'] 형식으로 기입 :  기존 col이 남아있음
				** 'col'형식으로 기입 : 기존 col 삭제됨

		column 변경
			## 


	type변경
		df.col.astype(type)
			type으로 변경가능
				*datetime으로 변경불가

		pd.to_numeric(df['col명'],errors='coerce')
			int로 변경  + 불가한 값있어도 무시하고 진행

		datetime
			pd.to_datetime(df[col])
				*응용     1)요일 : dt.dayofweek					
					2)pd.date_range(시작일자,종료일자) : 사이기간 자동출력(마지막날도 포함)

	값 정렬
		df.sort_values('col', ascending = Fales,)
			*col : col의 값을 기준으로 정렬 / by=['col']으로 기입가능

	null처리
		null 위치확인(+갯수확인)
			pd.isnull(df)
				: null값일 때 True
				 + 응용 : .sum() 해서 null갯수 출력

		대안값 넣기

			df.fillna('대신할값')
				:null을 넣어줌
				*값 대신 1)ffill : 위의 값 넣기  2)bfill : 아랫값 넣기
				*df[''] = df.col.fillna(df['col'])
					:특정 col의 nan값을 다른 col값으로 체울때 사용
			df.interpolate()
				: 선형근사값 넣어줌

		제거
			1. df 전체 기준
				df.dropna(axis = 0 or 1)
					:null이 포함된 row를 제거  (axis = 1  => col제거)

			2. col 기준
				df[pd.notnull(df.col)]

		conda prompt
			설치 
				pip install missingno
			import
				import missingno as msno
			null값 표시
				msno.matrix(df)
			*using heatmap
				msno.heatmap(df) : null값의 element를 heatmap으로 표시
					: 동일값을 갖는 상위 대칭부분은 미표시

입력값 받기
	공통사항
		_, *L = map(int, input or sys..)
			: 첫번째 입력값은 _에 대입, 나머지 입력값들을 L이라는 list로 넣어서 출력

	input()
		: 외부 입력값 받을 수 있음.
	
	sys.stdin.readline()
		: input과 동일하나 속도가 빠름.
		: 단일행을 받을 때 /n도 같이 출력되니 조심
		** import sys 필요
		
map
	map(function, list or tuple or ..)
		: 뒤에 들어오는 list에 요소들을 fuction 처리하여 list로 반환
			# 특정 개수의 변수 , *L 할경우 앞의 변수 갯수만큼 변수처리 이후 나머지 요소들은 하나의 list로 처리
   
zip
	zip(list1, list2..)
		: list에서 요소를 하나씩 뽑아서 tuple로 반환
		: list 갯수만큼 l1, l2... in zip(list1,list2...) 할 경우 각 변수에 들어감.	

반복문
	for
		**실수주의**
			num+=1 식의 count를 할때 for문안에 넣으면 무한루프에 걸림.
		
		작업진도 표시바(tqdm_notebook)
			import
				from tqdm.notebook import tqdm
			사용법
				ex)  for i in tqdm(range(숫자)):
					=> for 하나가 끝날때마다 진행률이 표시됨
		
		enumerate
			: list의 요소를 가져오면서 index를 자동으로 붙힐때 사용
			ex) for i, l in enumerate(list, ##) ==> i = index, l= 요소값으로 적용됨
				## : index시작을 변경가능 (defualt = 0)


제한문
	continue
		: 강제적으로 다음 loop를 돌리게 함.
	
	pass
		: 실행할 코드가 없다는 의미, 단순히 코드안에 TRUE 적는 것과 다를게 없음.

Try(예외처리)
	: error가 발생하는(예상되는) 코드 처리
	# 사용방법
	try :
		문제예상되는 코드 작성
	except ##:
		error가 발생시 실행할 코드
		## 안에 특정 error를 적어서 error별 처리를 다르게 할 수 있음
	else :
		error가 발생하지 않았을 때 실행할 코드
	finally : 
		error 유무와 상관없이 try 종료 후 실행할 문장
		
Txt 파일 생성 / 읽기
	text = open('파일명.txt', #)
		# : r = 읽기모드 / w = 쓰기모드 / a = 추가모드(마지막줄에 추가로 작성)
		
	text.read()
		: 전체 text 한번에 불러옴.
	
	close (종료)
		text.close()
			: 관련하여 종료 
			## 생략가능 / 쓰기모드 -> 다시 사용시 error발생하므로 사용하는게 좋음
			
정규표현식
	import re
	
	re.complie('str', ##)
		: str을 컴파일함.
			# str => r'str' 식으로 사용하는 것을 추천(\문자 이슈 자동 해결)
		## option
			re.DOTALL(S) 		: '.'이 줄바꿈(\n)을 포함하여 모든 문자와 매치할 수 있도록 한다.
			re.I(=re.IGNORECASE) 	: 대소문자에 관계없이 매치할 수 있도록 한다.
			re.M(=re.MULTILINE)	: 여러줄과 각각 매치 가능 -- (^, $ 메타문자의 사용과 관계가 있는 옵션이다)
			re.X(=re.VERBOSE)	: verbose 모드를 사용 (정규식을 보기 편하게 변환 가능 --주석(#) 사용 가능)
		
		.match()	: 문자열의 처음부터 정규식과 매치되는지 조사한다. (없으면 None)
				: if 문에 많이 사용함.
				: re.match(메타문자, str) 형식으로 사용가능
				
			.group()	매치된 문자열을 돌려준다.
			.start()	매치된 문자열의 시작 index를 돌려준다.
			.end()		매치된 문자열의 끝 index를 돌려준다.
			.span()		매치된 문자열의 (시작, 끝)에 해당하는 튜플을 돌려준다.		
		
		.search()	: 문자열 전체를 검색하여 정규식과 매치되는지 조사한다.
			(# match와 동일)
			.group()	매치된 문자열을 돌려준다.
			.start()	매치된 문자열의 시작 index를 돌려준다.
			.end()		매치된 문자열의 끝 index를 돌려준다.
			.span()		매치된 문자열의 (시작, 끝)에 해당하는 튜플을 돌려준다.		
			
			
		.findall()	: 정규식과 매치되는 모든 문자열(substring)을 리스트로 돌려준다.
		.finditer()	: 정규식과 매치되는 모든 문자열(substring)을 반복 가능한 객체로 돌려준다.
	
	meta char (메타문자)
		[#] : #와 동일한 문자 매치
			## 참고표현
				- : 구간설정 범위사용가능
				ex) 	[0-5] = [012345]
					[a-zA-Z] = 알파벳전체
					[0-9] = 숫자
				
				^ : not 의미
				ex)	[^0-9] = 숫자가 아닌 문자
				
		\ : 별도 표기법  # 대문자는 소문자의 반대
			\d : 숫자  = [0-9]
			\D : \d 반대
			\s : whitespace = [ \t\n\r\f\v]
			\S : \s 반대
			\w : 문자+숫자(alphanumeric)와 매치, [a-zA-Z0-9_]와 동일한 표현식이다.
			\W : \w 반대
			\A : 첫문자	# ^과 차이점 : re.M 사용시 ^은 줄마다 첫문자를, \A는 첫줄의 첫문자만 매치
			\Z : 마지막문자	# $ 차이점 : re.M 사용시 $은 줄마다 마지막, \Z는 문장전체의 마지막 문자 매치
			\b : 구분자(보통 whitespace) # 주의 : r''형태로만 사용할 것.
			\B : \b반대(구분자 아닌 경우 의미)
			\\ : 문자 '\' 표현
		
		. : '\n' 을 제외한 모든 한개 문자 
			## '\n'은 re.DOTALL 옵션으로 포함가능
		
		* : 문자 반복(0번 포함)
		+ : 문자 반복(0번 제외)
		? : 없거나 한번 쓰거나
		{00,00} : 00 ~ 00번 반복
			# {1,} = + 
			# {0,} = *  
			# {0,1} = ?
			# {2} = 2번반복만 매칭
			# {2,5} = 2~5번 반복 매칭
			
		| : or 
		^ : 첫문자		# '^str'으로 사용
		$ : 마지막문자	# 'str$'으로 사용
			
		() : 그루핑	# ()안의 단어를 묶어줌
			# .group()으로 그루핑하여 출력 가능
				-- group안에 group을 만들시 index는 안으로 들어갈수록 1씩증가 --> [0][1]으로 선택하지 않음

sample data
	sklean.datasets : 분류모델에 좋은 sample 제공
		import
			from sklearn.datasets import make_blobs 
			data = make_blobs(n_samples=200, n_features=2, centers=4, cluster_std = 1.8, random_state=111)
				# clustering sample 생성
	keras
		import
			from tensorflow import keras
		
		데이터 로드, 설정
			(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
			## 변수가 train, test로 알아서 나눠짐

ML
	train, test data 분류
		import 
			from sklearn.model_selection import train_test_split

		x_train, x_test, y_train, y_test =  train_test_split(x,y **)
			** test_size = 00 : 00비율만큼 test_size 지정
				# 기본값 = 0.25
			** random_state = 00 : 랜덤추출 고정   # 숫자값 무관

	정규화
		import
			from sklearn.preprocessing import StandardScaler

		ss = StandardScaler()
			#사용함수

			.fit_transform(##)
				## 안에 pandas or array 값들을 기준으로 정규화
				#주의# fit_transform을 각각 쓰다보면 오히려 정규화를 각자 기준으로 실시해서 오류가 발생함. fit은 한번 기준잡을 셈플에만 사용할 것.
			.transform(##)
				## fit 되어있는 기준으로 정규화 시켜줌		
			
	LinearRegrssion(선형회귀)
		import
			import sklearn.linear_model import LinearRegrssion
		
		lr_model = LinearRegression()
			: LinearRegression 사용시 변수설정
		
			#사용함수(lr_model 뒤에 함수 붙혀서 사용)
				.fit(x_train, y_train) : 선형근사 (알고리즘 생성)
					## fit을 한 후 밑의 함수들 사용 가능

				.predict(x_test) : x_test의 값들의 예측값 출력
					# 변수로 받아서 실제값과 비교하는데 사용

				.coef_ : 변수별 계수 출력
				.intercept_ : 선형근사의 y축절편
				.score(x_test, y_test) : R^2 추출

	KNeighborsClassifier(KNN, 근접값으로 분류하는 방법)
		import
			from sklearn.neighbors import KNeighborsClassifier

		knn = KNeighborsClassifier(n_neighbors = 00)
			# n_neighbors = 00 : 00개 만큼 뽑아서 중앙결정

			# 사용함수 (knn 뒤에 붙혀서 사용)
				.fit(x_train, y_train) : knn의 알고리즘 생성
				.predict(x_test) : x_test의 값들의 예측값 출력
					# 변수로 받아서 실제값과 비교하는데 사용

	LogisticRegression(이진법으로 분류 분석)
		import
			from sklearn.linear_model import LogisticRegression
		log = LogisticRegression()
			# 사용함수(log 뒤에 사용)
				.fit(x_train, y_train)
				.predict(x_test)

	DecisionTreeClassifier(의사결정나무)
		import
			from sklearn.tree import DecisionTreeClassifier
		tree = DecisionTreeClassifier()
			# 사용함수(tree 뒤에 사용)
				.fit(x_train, y_train)
				.predict(x_test)
				.feature_importances_
					: 요소별 중요도 추출

	Support Vector Machine(SVC) : 분류모델
		import
			from sklearn.svm import SVC
		svc = SVC()
			# 사용함수(svc 뒤에 사용)
				.fit(x_train, y_train)
				.predict(x_test)

	K_means
		import
			from sklearn.cluster import KMeans
		km = KMeans(n_clusters=4)
			# n_clusters = 00 : 00개로 분류
			# 사용함수(km 뒤에 사용)
				.fit(data)
					# data : x,y좌표로 묶인 값들의 모임
					         : df, array 등
				.cluster_centers_ : 00 개의 중점 출력
				.labels_  : data들의 추측값 출력	
				.predict(x_test)

	RandomForestClassifier(Bagging + decision tree)
		import
			from sklearn.ensemble import RandomForestClassifier
		rfc = RandomForestClassifier(#)
			# n_estimators = 00 : 00개의 뿌리 생성(기본값 100)
			# 사용함수(log 뒤에 사용)
				.fit(x_train, y_train)
				.predict(x_test)
		
	결과값 정확도 확인
		metrics
			# 사용 : LinearRegrssion / 
			import 
				from sklearn import metrics 

			사용가능 함수
				metrics.mean_squared_error(y_test, predictions)
						: mean_squared_error(=MSE) 추출
						# predictions : x_test로 추측해서 나온 y값
						# np.sqrt(MSE) : RMSE 값 추출

				metrics.mean_absolute_error(y_test, predictions)
					: MAE( = error절대값으로 합) 추출

				metrics.r2_score(y_test, predictions)
					: R^2 추출

		confusion_matrix, classification_report
			# 사용 : knn /
			import
				from sklearn.metrics import ##
					##
					  종류 :  confusion_matrix, classification_report, accuracy_score
					  * 을 쓰면 가능한 함수를 한번에 import 가능
					
			사용가능 함수
				confusion_matrix(y_test, predictions)
					: [[TN, FP],[FN, TP]]로 추출

				print(classification_report(y_test, predictions))
					: precision, recall, f1-score, support 값 추출

	하이퍼파라미터 선택방법
		GridSearchCV
			import
				from sklearn.model_selection import GridSearchCV
			변수설정
				params = {##} => dict형식으로 계산해보고자 하는 변수값을 list에 넣어서 value로 설정
					## ex)
						n_estimators : [300, 500]
						max_features : ['auto','sqrt']

				grid = GridSearchCV(##)
					## 순서 : 분석기법, param_grid ...(기본설정값)
						ex) RandomForestClassifier(), param_grid = params, refit = True , verbose=True, cv = 3 
					# 함수
					grid.fit(x_train, y_train) : 주어진 변수들로 계산
					# fit 다음으로 사용가능 함수
					grid.best_parmas_ : 최적의 설정 추출
					grid.best_score_ : 최고의 적중률
				
MySQL
	import
		import MySQLdb as ms

	db설정
		db = ms.connect('localhost','SQL_ID','SQL_Password','Database명', charset = 'utf8')
			#charset = 'utf8'은 오류에 따라 생략되고 작성됨

		함수
			cursor = db.cursor() : 데이터베이스에 명령 전달하는 객체

				cursor.execute(' ** ') : ' ** '를 mysql에서 쓴것과 비슷한 출력
					** show databases;  :  database 갯수 출력
					** show tables; : table 갯수 출력
					** insert~ : table에 값 넣기 가능

				cursir.exectemany(sql, data) : 데이터 다수를 입력, 수정시
					# data = [[ ],[ ],[ ]...] 형태로 []안에 raw하나씩
			
				cursor.fetchall()  : 모든 데이터 출력
					# show databases 후 : databases 목록출력
					# Placeholder => %s로 문자, 숫자 모두 지정가능
						##url참고 :  https://yurimkoo.github.io/python/2019/09/14/connect-db-with-python.html 

				cursor.fetchone()  : 한번 호출에 한개의 행만 출력
				cursor.fetchany(00)  : 00개 데이터 출력

			db.commit()
				: table생성 및 insert한 후 commit()해야 DB에 반영됨.


	table 불러오기
		pd.pandas_sql('select * from table명;' , db)
			# 'select 이후 MySQL 편집기능 사용가능
			## col명 변경, where 동시사용시 : table을 두번적음
				select ascol명 from (select col명 ascol명 from table) table where 조건 
				
MariaDB
	import pymysql
	
	db 연결
		con = pymysql.connet(host = 'IP주소입력', user = 'userID', password = 'password', db = 'db명' , charset = 'utf8'
		cur = con.cursor()
	
	sql문 작성
		cur.execute(sql)
			: 입력한 sql 결과에 따른 갯수를 출력함
	
	table 저장
		cur.execute('select * from table')
		table = cur.fetchall()

scipy
	import
		: import scipy as sp
		+ from scipy import stats

	sp.amax() : ()안의 최댓값

	sp.amin() :  ()안의 최솟값

	sp.median() : ()안의 중간값

	sp.var() == np.var()
	sp.std() == np.std()

stats
	import
		: from scipy import stats
	
	stats.norm.pdf(loc=00, scale=00 ,x=00) 
		: loc = 평균, sacle = 표준편차, x 값이 나올 확률 추출

	stats.norm.cdf(loc=4,scale=0.8, x=3)  
		: loc = 평균, sacle = 표준편차, x 값의 누적확률값 추출

	stats.norm.ppf(loc=00, scale=00, q=00)   
		=> loc = 평균, sacle = 표준편차, q 확률이 되는 x값 추출

	stats.t.ppf(q = 0.975, df = 9) 
		=> q = 원하는 확률값, df = 자유도인 t분포 값 추출
		* q=.975 => .25의 t_value 값

	stats.t.cdf(t,df)
		: 정규화값과 자유도를 기반으로 t분산에서 t값의 누적확률값 추출
		* t : 정규화한 값 / df : 자유도
		*1 - 추출값*2 : p_value(양측검정시)

	stats.t.interval(alpha = 0.95, df=9, loc=np.mean(fish), scale = se)
		: alpha = 신뢰구간, df = 자유도, scale = 표준오차

	stats.ttest_1samp(표본array, 모평균)
		: t_value, p_value 출력 (t_value :검정통계량, p_value : 확률(유의수준과 비교하는 값))
		* t분포

	stats.ttest_rel(arr1, arr2)
		: 쌍체검정 함수(arr1, arr2 비교)
		* 쌍체검정 : 약복용 전후 비교 같이 동일한 집단의 결과 비교

	stats.ttest_ind(arr1, arr2 , **)
		: 이집단 검정
		** equal_var = False : 모분산이 다를때 넣음 / 기본값 : 모분산 동일

	stats.norm.rvs(loc=00, scale = 00, size = 00)
		: 평균과 표준편차를 정한 정규분포에서 랜덤추출
		* loc : 평균, scale : 표준편차, size : 추출할 갯수

	회귀분석
		import
			import statsmodels.formula.api as msf
			import statsmodels.api as sm

		smf.ols(formula = 'col명 ~ col명',data=df).fit()
			: 종속변수 ~ 독립변수로 분석을 실시함
 			: 독립변수를 여러개 할경우 col명 + col명 식으로 넣음
			* .summary()를 붙혀서 표로 출력가능
* summary 의미
# beer : 종속변수
# temperature : 독립변수


# R-squrared  : data가 많아질 수록 높아짐
# Adj
# F-statistic : F비
# Prob(F) : p_value  => 유의수준과 비교

# Log_Likelihood : ??
# AIC : ??
# BIC : ??

#Df Residuals : 잔차 자유도
#Df Model : 자유도



#         coef
#inter    계수
#temper   계수

# Skew : 잔차의 좌우측 처짐(-+)

		분산분석
			sm.stats.anova_lm(lm_ , **)
				: sum_sq, 자유도, F비, p_value 추출
				* lm_ : smf.ols한 변수 넣음
				** typ = 1 : 단일변수 분산분석
				   typ = 2 : 다중변수 분산분석		

numpy
	import
		import numpy as np : np로 줄여씀

	# 함수
		np.load(*) :  확장자가 .npy인 파일을 불러들임
		
		np.array(*) : *을 array로 변환

		np.concatenate((arr1, arr2), ##) : array 합산
			##
				axis = 1  : 열을 늘려줌
				axis = 0 : 행을 늘려줌

		np.percentile(list or df...  , *) : *에 해당하는 percentile 값 출력
			* 50, 75 등 숫자 기입 / 복수기입시 []로 묶음

		df[col].corr(df[col1]) : col & col1의 상관계수

		df[col].cov(df[col1]) : col & col1의 공분산

		df.std(ddof=0)  * ddof=0 을 붙혀야 오차가 발생하지 않음
		
		np.random.seed(#)				
			# : int값을 넣어서 랜덤성을 지정할 수 있음
			
		np.random.randint(#)
			# : int(= 랜덤 범위지정)
			  : size = 00 : 00개 추출(list 반환)
		
		np.random.shuffle(#)
			: # 을 seed에 맞게(없으면 랜덤) 섞음.

		np.random.choice(df , size = 10, replace = False)
			: df에서 10개를 랜덤으로 추출

		np.arange(start = 00, stop = 00 , step = 00)
			: start숫자부터 stop전까지(stop값은 안나옴) step만큼 차이로 추출(array형태)
			* range와 다르게 소수점 단위로 step을 결정할 수 있음

		np.zeros(00 **)
			: 00개의 0값을 갖는 array 생성
			** dtype = 'bool' 입력시 00개의 False를 갖는 array출력

		np.tile('str', 00)
			: 'str'을 00개 갖는 array 생성

		np.unique(#, ##)
			# : list, array 등의 unique 출력
			##
				return_counts = True : unique의 갯수들 같이 출력
		
		array or list 합치기
			np.stack((list1,list2))
				: list1하단에 list2를 붙힘

			np.vstack(list1, list2)
				: list1하단에 list2를 붙힘
				## stack과 동일

			np.hstack(list1, list2)
				: list1 좌측에 list2를 붙힘

		array or list 분할
			np.split(분할할 요소, 기준)
				: 기준에 맞게 요소를 나눔(기준이 list도 가능)
			
			np.vsplit(분할할 요소, 기준)
				: 기준을 list로 줌, list안에 숫자만큼 위아래로 잘라냄(잘라내는 만큼 변수설정이 편함)

		np.column_stack((list1, list2))
			: 각 list에서 한개씩 뽑아서 list로 만든후 2차원 array로 출력

pandas
	Series
		pd.Series(list, index=[])           * 주의 *  S대문자, index=[]

		Series.apply(pd.Series.last_valid_index)    : nan이 아닌 index 중 가장작은 값을 추출
			*원본미반영
			*Series대신 df를 사용할 경우 col별로 출력

		문자존재여부확인**정규표현식
			.str.contains('글자')
				*bool형식으로 출력
				*'(|)' 식으로 한글자를 여러가지로, 여러단어를 한줄로 가능
			.str.split(' ', expand = True)
				*apply사용하지 않고 split가능
				*expand = True : split한 값들을 dataframe으로 만듬
		
		요소값 갯수확인
			df.col.value_counts(sort=False)
			*sort=False 하면 정렬하지 않음

		DataFrame으로 변경
			.to_frame()
				:series를 dataframe으로 변경

	

	pivot_table  : 시각적으로 가장 이쁘게 나옴
		pd.pivot_table(df, index=''(2개이상일때는 []안에),values = '')

	melt 
		pd.melt(id_vars='col' var_name = '', value_name = '')
			* id_vars : 기준 col / 나머지 col을 var_name col에 넣고 대칭하는 값들을 value_name으로 넣음
			* var_name : 다른 col들의 명칭을 넣는 col의 이름 지정
			* value_name : 대칭되는 값들을 넣는 col의 이름지정

	문자 수치화
		pd.get_dummies(#) : 알고리즘학습시 string을 숫자로 변환하는 함수
			# list, dataframe가 들어감(type = string인 data..)

plot
	Size(크기)
		plot 동시표시설정
			f, (ax1, ax2) = plt.subplots(1,2, sharey = True , figsize = (00,00))
				: ax1, ax2로 해서 각각의 설정 가능

		plot 크기조절
			plt.figure(figsize = (15,8))

	axis(축)
		축의 데이터 값 범위 조정
			plt.ylim(0, 40000)  => y축의 데이터 범위 0~40000으로 조정
			
		축의 표시값 설정
			plt.xticks(**) : ()의 값으로 x축 표시 변경
				## ()안에는 x축의 값을 넣어야 함.
				
		labeling(이름 작성)
			plt.xlabel('') : x축 이름작성
			plt.ylabel('') : y축 이름작성
		
		delete(축 없애기)
			plt.axis('off')
			
	범례(그래프별 설명)
		remove(범례제거)
			plt.legend().remove()

	그래프 종류
		scatterplot
			.plot(kind='scatter',x='경도',y='위도') : 좌표에 점들료 표시
				# 위치표시(지도) 등에 활용
			plt.scatter(x, y, ##)
				# x, y 에 맞는 list, array를 넣어서 표시
				## c = 00 : 색상조절
				## cmap : ??

		boxplot  : 데이터 분포파악에 효과적
			.plot(kind = 'box')


seaborn (시각적인 표현은 가장 이쁨)
	import seaborn as sns
	전체적 공통점
	1) ()안에 color = '' 으로 색조정 가능

	sns.countplot(data = df, x= col명)		 
		: col의 갯수를 bar차트로 표현

	sns.jointplot(data = df, x=col , y = col)
		: 값들의 dot + 좌표밖으로 bar 표시

	sns.barplot(data = df , x= 'col명', y = 'col명' )
		=> x와 y 기준에 해당하는 값들의 평균으로 bar표시

	sns.relplot(data = df, x = 'col', y = 'col',kind = 'line')  : line plot

	sns.scatterplot(data = df , x = 'col명', y = 'col명', hue= 'col명')
		*hue : 세부적으로 나누기 원하는 col / 다른색상 및 기준 표시됨.

	sns.boxplot(data = df, x= 'col명', y= 'col명')

	sns.violinplot(data = df , x= 'col명', y= 'col명')
		: box와 비슷, 라인으로 표현

	sns.heatmap(df, cmap = '색상', annot = True, fmt='0.f')
		*annot : 박스안에 숫자표시
		*fmt : 소수점표시 기준

	sns.distplot(df.col **)
		: 해당 col의 값들의 분포를 보여줌 (bar 와 line으로 출력)
		** bins = 00 => x축의 단위를 조정
		***활용 : array를 활용 pdf 그릴때 활용

	sns.lmplot(data = df ,x=col명 ,y=col명, scatter_kws = {'color' : 'black'}, line_kws = {'color' : 'black'})
		: scatter와 선형추정, 분포 표시
		* scatter_kws : 선 색을 지정
		* line_kws : 선 주변의 색 지정

	sns.pairplot(data = df)
		:df의 col들을 2개씩 묶어서 scatter한 그래프 추출

folium
	import folium
	좌표 지도찾기
		folium.Map(location = [lat, long], zoom_start=15, tiles = '**')
			* lat = 경도, long = 위도
			* zoom_start = 확대크기
			** 'Stamen Terrain' : 지도의 입체감
			   'CartoDB positron' : 지도를 흐릿하게 함
			   'CartoDB dark_matter' : 지도를 검은색으로 변환	


	해당좌표에 커서표시
		m =folium.Map(location = [lat, long], zoom_start=15)

		folium.Marker(***).add_to(m)
		folium.CircleMarker(***).add_to(m) : marker를 원으로 표시
		m
			***에 들어가는 내용:
				[lat, long] : 위도, 경도
				tooltip = '' :  커서를 올렸을때 나오는 글

				Marker에서만 사용
					 icon=folium.Icon(**)
					**icon='star' : icon모양을 별모양으로 변경
				 CircleMarker에서만 사용
					color = ' ' : 원의 지름색
					fill = True, fill_color = '  ', radius= 숫자, fill_opacity=숫자 : 원 내부 색 체움 / 내부색/내부원의 크기 / 내부원색의 투명도

	저장
		m.save('파일명.html')

	표현값이 많을때 일정범위 숫자로 표시
		from folium.plugins import MarkerCluster
		m = folium.Map([lat,long], zoom_start = 12)  * m : 이미 지정해둔 값으로
		Marker_cluster = MarkerCluster().add_to(m)
		**마지막 folium.Marker에 M대신 Marker_cluster로 변경

크롤링
	import
		from bs4 import BeautifulSoup as bs
		from selenium import webdriver
		from selenium.webdriver.common.keys import Keys   # 단어입력시 필요

	selenium
		selenium설치
			anacomda prompt에서 설치
				pip install selenium

		import
			from selenium import webdriver

		webdrive사용
			driver 열기
				driver = webdriver.Chrome(''파일위치'\\chromedriver.exe')

			창크기 설정
				driver.set_window_size(가로,세로)
				* 일부가 화면에 짤려서 실행안되는 상황을 해결

			driver.get(url)
				url = '원하는 인터넷 주소' 주소창에 입력 및 검색

			html sorce code 
				html = driver.page_source

		경로 검색
			id
				driver.find_element_by_id('id')		
			class
				driver.find_element_by_class_name('class명')		
			tag
				driver.find_element_by_tag_name('tag명')	
			글자
				driver.find_element_by_link_text('글자').click()
			xpath
				driver.find_element_by_xpath('xpath주소')

		클릭
			driver.find_element_by_link_text('대상의 글자').click()

		단어입력
			import
				from selenium.webdriver.common.keys import Keys
			
			입력방법
				경로.send_keys('입력단어')
				예시)				
					driver.find_element_by_id('원하는 경로 id').send_keys('단어')
				enter
		
		팝업창
			import
				from selenium.webdriver.chrome.options import Options

			켜있는 창 목록 출력(list)
				driver.window_handles
			
			window 바꾸기
				driver.switch_to_window(driver.window_handles[##])
				##
					숫자입력, 0 : 본래, 1~ : 팝업(아닐수 있음)
					팝업을 끈후에 본래 창으로 switch해줘야 함
			window 끄기
				driver.close()		 	

	BeatifulSoup
		import
			from bs4 import BeatifulSoup as bs
		parser
			soup = bs(html, 'html.parser')
				*html = driver.page_source

			soup.select('경로 ex)div > ul')
				* <  >안의 글자는 .select('  ')
				* 속성(<>표시없는)은 [  ]로 (.select 사용 x)
					** 활용 : class이름 추출때도 ['class']
				* id = #  / class = .  / 기타속성 = []
				
		text만 추출
			.text
				*error 발생시 문자열이 맞는지 확인할 것(list일 확률 높음)

	time
		import
			import time
		time.sleep(숫자)  * 2~3 추천
			*page를 완전히 못읽었을 때 
text mining
	from konlpy.tag import Okt
	
	# 명사추출
		okt = Okt()
		okt.nouns(분석할str)
	
